#!/usr/bin/env python3
"""
Yandex Maps - Veri Temizleyici ve Duplicate Ã–nleyici
Path: data_cleaner.py

Bu script, Ã§ekilen yorum verilerindeki sorunlarÄ± temizler:
1. Tekrarlanan kayÄ±tlarÄ± Ã§Ä±karÄ±r
2. BoÅŸ alanlarÄ± dÃ¼zeltir 
3. Veri kalitesini iyileÅŸtirir
"""

import os
import pandas as pd
import json
import re
from datetime import datetime
import logging

# Logging ayarlarÄ±
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("data_cleaner.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class YandexDataCleaner:
    def __init__(self):
        self.input_file = None
        self.output_file = None
        self.df = None
        self.total_records = 0
        self.duplicate_count = 0
        self.empty_fields_count = {
            'author_name': 0,
            'text_original': 0,
            'date': 0,
            'rating': 0
        }
        
    def load_data(self, file_path):
        """CSV veya JSON dosyasÄ±ndan veri yÃ¼kle"""
        logger.info(f"ğŸ“‚ Dosya yÃ¼kleniyor: {file_path}")
        self.input_file = file_path
        
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext == '.csv':
            self.df = pd.read_csv(file_path, encoding='utf-8-sig')
        elif file_ext == '.json':
            # JSON dosyasÄ±nÄ± aÃ§
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # JSON iÃ§inden reviews listesini al
            if isinstance(data, dict) and 'reviews' in data:
                reviews = data['reviews']
            else:
                reviews = data
                
            # DataFrame'e Ã§evir
            self.df = pd.DataFrame(reviews)
        else:
            raise ValueError(f"Desteklenmeyen dosya formatÄ±: {file_ext}")
            
        self.total_records = len(self.df)
        logger.info(f"âœ… {self.total_records} kayÄ±t yÃ¼klendi")
        logger.info(f"ğŸ“Š SÃ¼tunlar: {', '.join(self.df.columns)}")
        
        # SÃ¼tunlarÄ±n var olduÄŸunu kontrol et
        required_columns = ['review_id', 'author_name', 'text_original', 'date', 'rating']
        for col in required_columns:
            if col not in self.df.columns:
                logger.warning(f"âš ï¸ '{col}' sÃ¼tunu bulunamadÄ±!")
                
        return self.total_records
        
    def analyze_data_quality(self):
        """Veri kalitesi analizi yap"""
        logger.info(f"ğŸ” Veri kalitesi analizi yapÄ±lÄ±yor...")
        
        # BoÅŸ deÄŸerler
        for col in self.empty_fields_count.keys():
            if col in self.df.columns:
                empty_count = self.df[col].isna().sum()
                self.empty_fields_count[col] = empty_count
                empty_percent = (empty_count / self.total_records) * 100
                logger.info(f"  - {col}: {empty_count} boÅŸ deÄŸer (%{empty_percent:.1f})")
        
        # Tekrarlanan kayÄ±tlar
        if 'review_id' in self.df.columns:
            duplicate_ids = self.df['review_id'].duplicated().sum()
            logger.info(f"  - Tekrarlanan review_id: {duplicate_ids}")
            
        # DiÄŸer alanlar Ã¼zerinden tekrarlarÄ± kontrol et
        if 'author_name' in self.df.columns and 'text_original' in self.df.columns:
            duplicate_content = self.df.duplicated(subset=['author_name', 'text_original']).sum()
            logger.info(f"  - Ä°Ã§erik bazlÄ± tekrar: {duplicate_content}")
            
        # Ortalama metin uzunluÄŸu
        if 'text_original' in self.df.columns:
            self.df['text_length'] = self.df['text_original'].fillna('').apply(len)
            avg_length = self.df['text_length'].mean()
            logger.info(f"  - Ortalama yorum uzunluÄŸu: {avg_length:.1f} karakter")
            
        # PuanlarÄ±n daÄŸÄ±lÄ±mÄ±
        if 'rating' in self.df.columns:
            rating_counts = self.df['rating'].value_counts(dropna=False)
            logger.info(f"  - Puan daÄŸÄ±lÄ±mÄ±:\n{rating_counts}")
            
        return {
            'empty_fields': self.empty_fields_count,
            'duplicate_ids': duplicate_ids if 'review_id' in self.df.columns else 0,
            'duplicate_content': duplicate_content if 'author_name' in self.df.columns and 'text_original' in self.df.columns else 0,
            'avg_text_length': avg_length if 'text_original' in self.df.columns else 0
        }
    
    def clean_data(self):
        """Veriyi temizle"""
        logger.info(f"ğŸ§¹ Veri temizleme iÅŸlemi baÅŸlatÄ±lÄ±yor...")
        original_count = len(self.df)
        
        # 1. Tekrarlanan kayÄ±tlarÄ± Ã§Ä±kar
        if 'review_id' in self.df.columns:
            # review_id'ye gÃ¶re tekrarlarÄ± Ã§Ä±kar
            before_count = len(self.df)
            self.df = self.df.drop_duplicates(subset=['review_id'])
            removed = before_count - len(self.df)
            if removed > 0:
                logger.info(f"âœ“ {removed} tekrarlanan review_id Ã§Ä±karÄ±ldÄ±")
                self.duplicate_count += removed
        
        # 2. Ä°Ã§erik bazlÄ± tekrarlarÄ± Ã§Ä±kar
        if 'author_name' in self.df.columns and 'text_original' in self.df.columns:
            before_count = len(self.df)
            self.df = self.df.drop_duplicates(subset=['author_name', 'text_original'])
            removed = before_count - len(self.df)
            if removed > 0:
                logger.info(f"âœ“ {removed} iÃ§erik bazlÄ± tekrar Ã§Ä±karÄ±ldÄ±")
                self.duplicate_count += removed
                
        # 3. BoÅŸ kullanÄ±cÄ± adlarÄ±nÄ± dÃ¼zelt
        if 'author_name' in self.df.columns:
            empty_authors = self.df['author_name'].isna() | (self.df['author_name'] == '')
            self.df.loc[empty_authors, 'author_name'] = "Anonim KullanÄ±cÄ±"
            logger.info(f"âœ“ {empty_authors.sum()} boÅŸ kullanÄ±cÄ± adÄ± 'Anonim KullanÄ±cÄ±' olarak deÄŸiÅŸtirildi")
            
        # 4. BoÅŸ yorumlarÄ± filtrele veya iÅŸaretle
        if 'text_original' in self.df.columns:
            empty_text = self.df['text_original'].isna() | (self.df['text_original'] == '')
            # SeÃ§enek 1: BoÅŸ yorumlarÄ± Ã§Ä±kar
            # self.df = self.df[~empty_text]
            # logger.info(f"âœ“ {empty_text.sum()} boÅŸ yorumlu kayÄ±t Ã§Ä±karÄ±ldÄ±")
            
            # SeÃ§enek 2: BoÅŸ yorumlarÄ± iÅŸaretle
            self.df.loc[empty_text, 'text_original'] = "[BoÅŸ yorum]"
            logger.info(f"âœ“ {empty_text.sum()} boÅŸ yorum iÅŸaretlendi")
        
        # 5. Metin iÃ§eriÄŸini temizle
        if 'text_original' in self.df.columns:
            # Fazla boÅŸluklarÄ± temizle
            self.df['text_original'] = self.df['text_original'].fillna('').apply(
                lambda x: re.sub(r'\s+', ' ', x).strip()
            )
            
            # YaygÄ±n olarak bulunan gereksiz metinleri temizle
            common_texts = ["Abone ol", "Subscribe", "VarsayÄ±lan", "Default", "Deneyimini paylaÅŸ"]
            for text in common_texts:
                self.df['text_original'] = self.df['text_original'].str.replace(text, '', regex=False)
                
            logger.info(f"âœ“ Yorum metinleri temizlendi, gereksiz iÃ§erikler Ã§Ä±karÄ±ldÄ±")
        
        # 6. PuanlarÄ± normalleÅŸtir
        if 'rating' in self.df.columns:
            # MantÄ±ksÄ±z deÄŸerleri dÃ¼zelt (Ã¶rn. 66.0 gibi)
            invalid_ratings = self.df['rating'] > 5
            if invalid_ratings.any():
                logger.info(f"âš ï¸ {invalid_ratings.sum()} geÃ§ersiz puan deÄŸeri tespit edildi")
                
                # 5 Ã¼zeri puanlarÄ± normalize et - Ã¶rneÄŸin 66.0 -> None
                self.df.loc[invalid_ratings, 'rating'] = None
                logger.info(f"âœ“ GeÃ§ersiz puanlar temizlendi")
        
        # 7. Tarih formatÄ±nÄ± normalize et
        if 'date' in self.df.columns:
            # Tarih formatÄ±nÄ± dÃ¼zelt veya eksik tarihleri iÅŸaretle
            empty_dates = self.df['date'].isna() | (self.df['date'] == '')
            self.df.loc[empty_dates, 'date'] = 'Tarih belirtilmemiÅŸ'
            logger.info(f"âœ“ {empty_dates.sum()} boÅŸ tarih iÅŸaretlendi")
            
        logger.info(f"ğŸ‰ Veri temizleme tamamlandÄ±! Ä°lk: {original_count}, Son: {len(self.df)}, Fark: {original_count-len(self.df)}")
        
        return len(self.df)
    
    def export_clean_data(self, output_path=None):
        """TemizlenmiÅŸ veriyi dÄ±ÅŸa aktar"""
        if output_path:
            self.output_file = output_path
        else:
            # VarsayÄ±lan isim oluÅŸtur
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            file_base = os.path.splitext(os.path.basename(self.input_file))[0]
            self.output_file = f"{file_base}_clean_{timestamp}.csv"
            
        logger.info(f"ğŸ’¾ TemizlenmiÅŸ veri kaydediliyor: {self.output_file}")
        self.df.to_csv(self.output_file, index=False, encoding='utf-8-sig')
        
        # Ã–zet bilgi yazdÄ±r
        print("\n" + "=" * 40)
        print(f"âœ… Veri temizleme tamamlandÄ±!")
        print(f"ğŸ“Š Ä°lk kayÄ±t sayÄ±sÄ±: {self.total_records}")
        print(f"ğŸ” Ã‡Ä±karÄ±lan tekrar kayÄ±t: {self.duplicate_count}")
        print(f"ğŸ“‹ Kalan kayÄ±t sayÄ±sÄ±: {len(self.df)}")
        print(f"ğŸ’¾ Temiz veri kaydedildi: {self.output_file}")
        print("=" * 40)
        
        return self.output_file

def main():
    print("\nğŸ§¹ Yandex Maps Veri Temizleyici")
    print("=" * 40)
    
    # Dosya seÃ§
    print("\nğŸ“ LÃ¼tfen temizlenecek veri dosyasÄ±nÄ± seÃ§in (CSV veya JSON):")
    
    # Mevcut dizindeki CSV ve JSON dosyalarÄ±nÄ± listele
    current_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(current_dir, "data", "processed")
    
    if not os.path.exists(data_dir):
        data_dir = current_dir
    
    files = [f for f in os.listdir(data_dir) if f.endswith(('.csv', '.json'))]
    
    if not files:
        print("âŒ HiÃ§ CSV veya JSON dosyasÄ± bulunamadÄ±!")
        return
    
    # DosyalarÄ± numaralandÄ±rarak gÃ¶ster
    for i, file in enumerate(files, 1):
        print(f"  [{i}] {file}")
    
    # Dosya seÃ§imi
    while True:
        try:
            choice = input("\nSeÃ§iminiz (numara): ").strip()
            file_index = int(choice) - 1
            
            if 0 <= file_index < len(files):
                selected_file = os.path.join(data_dir, files[file_index])
                break
            else:
                print("âš ï¸ LÃ¼tfen listeden geÃ§erli bir numara seÃ§in!")
        except ValueError:
            print("âš ï¸ LÃ¼tfen bir sayÄ± girin!")
    
    # Veri temizleyiciyi baÅŸlat
    cleaner = YandexDataCleaner()
    
    try:
        # Veriyi yÃ¼kle
        cleaner.load_data(selected_file)
        
        # Veri kalitesi analizi yap
        cleaner.analyze_data_quality()
        
        # Veriyi temizle
        cleaner.clean_data()
        
        # TemizlenmiÅŸ veriyi dÄ±ÅŸa aktar
        cleaner.export_clean_data()
        
    except Exception as e:
        logger.error(f"ğŸ’¥ Hata oluÅŸtu: {e}")
        print(f"\nâŒ Bir hata oluÅŸtu: {e}")

if __name__ == "__main__":
    main()